{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7121f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "829a489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/Mayuresh Chimankar/Desktop/Coding/RL Project/sudoko_dataset/sudoku.csv\")\n",
    "try:\n",
    "\tdata = pd.DataFrame({\"quizzes\": data[\"puzzle\"], \"solutions\": data[\"solution\"]})\n",
    "except:\n",
    "\tpass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "180baf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "\tdef __init__(self, df,batch_size = 16,subset = \"train\",shuffle = False, info={}):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.df = df\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.shuffle = shuffle\n",
    "\t\tself.subset = subset\n",
    "\t\tself.info = info\n",
    "\n",
    "\t\tself.on_epoch_end()\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn int(np.floor(len(self.df)/self.batch_size))\n",
    "\tdef on_epoch_end(self):\n",
    "\t\tself.indexes = np.arange(len(self.df))\n",
    "\t\tif self.shuffle==True:\n",
    "\t\t\tnp.random.shuffle(self.indexes)\n",
    "\n",
    "\tdef __getitem__(self,index):\n",
    "\t\tX = np.empty((self.batch_size, 9,9,1))\n",
    "\t\ty = np.empty((self.batch_size,81,1))\n",
    "\t\tindexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\t\tfor i,f in enumerate(self.df['quizzes'].iloc[indexes]):\n",
    "\t\t\tself.info[index*self.batch_size+i]=f\n",
    "\t\t\tX[i,] = (np.array(list(map(int,list(f)))).reshape((9,9,1))/9)-0.5\n",
    "\t\tif self.subset == 'train':\n",
    "\t\t\tfor i,f in enumerate(self.df['solutions'].iloc[indexes]):\n",
    "\t\t\t\tself.info[index*self.batch_size+i]=f\n",
    "\t\t\t\ty[i,] = np.array(list(map(int,list(f)))).reshape((81,1)) - 1\n",
    "\t\tif self.subset == 'train': return X, y\n",
    "\t\telse: return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "801b0362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 9, 9, 64)          640       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 9, 9, 64)          256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 9, 9, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 9, 9, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 9, 9, 128)         8320      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10368)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 729)               7559001   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 81, 9)             0         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 81, 9)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7605401 (29.01 MB)\n",
      "Trainable params: 7605145 (29.01 MB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same', input_shape=(9,9,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, kernel_size=(1,1), activation='relu', padding='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(81*9))\n",
    "model.add(Reshape((-1, 9)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec88b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mayuresh Chimankar\\AppData\\Local\\Temp\\ipykernel_21580\\214729483.py:20: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(training_generator, validation_data = validation_generator, epochs = 5, verbose=1,callbacks=callbacks_list )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13359/13359 [==============================] - ETA: 0s - loss: 0.4296 - accuracy: 0.1114\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10930, saving model to weights-improvement-01-0.11.hdf5\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10930, saving model to best_weights.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mayuresh Chimankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13359/13359 [==============================] - 4731s 354ms/step - loss: 0.4296 - accuracy: 0.1114 - val_loss: 0.3800 - val_accuracy: 0.1093 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "13359/13359 [==============================] - ETA: 0s - loss: 0.3749 - accuracy: 0.1113\n",
      "Epoch 2: val_accuracy improved from 0.10930 to 0.11143, saving model to weights-improvement-02-0.11.hdf5\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.10930 to 0.11143, saving model to best_weights.hdf5\n",
      "13359/13359 [==============================] - 4436s 332ms/step - loss: 0.3749 - accuracy: 0.1113 - val_loss: 0.3724 - val_accuracy: 0.1114 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "13359/13359 [==============================] - ETA: 0s - loss: 0.3691 - accuracy: 0.1113\n",
      "Epoch 3: val_accuracy did not improve from 0.11143\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.11143\n",
      "13359/13359 [==============================] - 5264s 394ms/step - loss: 0.3691 - accuracy: 0.1113 - val_loss: 0.3692 - val_accuracy: 0.1107 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "13359/13359 [==============================] - ETA: 0s - loss: 0.3656 - accuracy: 0.1113\n",
      "Epoch 4: val_accuracy did not improve from 0.11143\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.11143\n",
      "13359/13359 [==============================] - 4384s 328ms/step - loss: 0.3656 - accuracy: 0.1113 - val_loss: 0.3675 - val_accuracy: 0.1112 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "13151/13359 [============================>.] - ETA: 1:09 - loss: 0.3629 - accuracy: 0.1113"
     ]
    }
   ],
   "source": [
    "train_idx = int(len(data)*0.95)\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "training_generator = DataGenerator(data.iloc[:train_idx], subset = \"train\", batch_size=640)\n",
    "validation_generator = DataGenerator(data.iloc[train_idx:], subset = \"train\", batch_size=640)\n",
    "\n",
    "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\n",
    "filepath1=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "filepath2 = \"best_weights.hdf5\"\n",
    "checkpoint1 = ModelCheckpoint(filepath1, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "\tmonitor='val_loss',\n",
    "\tpatience=3,\n",
    "\tverbose=1,\n",
    "\tmin_lr=1e-6\n",
    ")\n",
    "callbacks_list = [checkpoint1,checkpoint2,reduce_lr]\n",
    "\n",
    "history = model.fit_generator(training_generator, validation_data = validation_generator, epochs = 5, verbose=1,callbacks=callbacks_list )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6802852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('C:/Users/Mayuresh Chimankar/Desktop/Coding/RL Project/best_weights.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaffa5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_sudoku_with_nn(model, puzzle):\n",
    "\t# Preprocess the input Sudoku puzzle\n",
    "\tpuzzle = puzzle.replace('\\n', '').replace(' ', '')\n",
    "\tinitial_board = np.array([int(j) for j in puzzle]).reshape((9, 9, 1))\n",
    "\tinitial_board = (initial_board / 9) - 0.5\n",
    "\n",
    "\twhile True:\n",
    "\t\t# Use the neural network to predict values for empty cells\n",
    "\t\tpredictions = model.predict(initial_board.reshape((1, 9, 9, 1))).squeeze()\n",
    "\t\tpred = np.argmax(predictions, axis=1).reshape((9, 9)) + 1\n",
    "\t\tprob = np.around(np.max(predictions, axis=1).reshape((9, 9)), 2)\n",
    "\n",
    "\t\tinitial_board = ((initial_board + 0.5) * 9).reshape((9, 9))\n",
    "\t\tmask = (initial_board == 0)\n",
    "\n",
    "\t\tif mask.sum() == 0:\n",
    "\t\t\t# Puzzle is solved\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tprob_new = prob * mask\n",
    "\n",
    "\t\tind = np.argmax(prob_new)\n",
    "\t\tx, y = (ind // 9), (ind % 9)\n",
    "\n",
    "\t\tval = pred[x][y]\n",
    "\t\tinitial_board[x][y] = val\n",
    "\t\tinitial_board = (initial_board / 9) - 0.5\n",
    "\n",
    "\t# Convert the solved puzzle back to a string representation\n",
    "\tsolved_puzzle = ''.join(map(str, initial_board.flatten().astype(int)))\n",
    "\n",
    "\treturn solved_puzzle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1db82d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sudoku_grid(puzzle):\n",
    "\tpuzzle = puzzle.replace('\\n', '').replace(' ', '')\n",
    "\tfor i in range(9):\n",
    "\t\tif i % 3 == 0 and i != 0:\n",
    "\t\t\tprint(\"-\"*21)\n",
    "\n",
    "\t\tfor j in range(9):\n",
    "\t\t\tif j % 3 == 0 and j != 0:\n",
    "\t\t\t\tprint(\"|\", end=\" \")\n",
    "\t\t\tprint(puzzle[i*9 + j], end=\" \")\n",
    "\t\tprint()\n",
    "new_game = '''\n",
    "0 0 0 0 0 0 0 0 0\n",
    "0 0 0 0 0 0 0 0 0\n",
    "0 0 0 0 0 0 0 0 0\n",
    "0 0 0 0 0 0 0 0 0\n",
    "0 0 0 0 0 0 0 0 0\n",
    "0 0 0 0 0 0 0 0 0\n",
    "0 0 0 0 0 0 0 0 0\n",
    "0 0 0 0 0 0 0 0 0\n",
    "0 0 0 0 0 0 0 0 0\n",
    "'''\n",
    "\n",
    "game = '''\n",
    "0 0 0 7 0 0 0 9 6\n",
    "0 0 3 0 6 9 1 7 8\n",
    "0 0 7 2 0 0 5 0 0\n",
    "0 7 5 0 0 0 0 0 0\n",
    "9 0 1 0 0 0 3 0 0\n",
    "0 0 0 0 0 0 0 0 0\n",
    "0 0 9 0 0 0 0 0 1\n",
    "3 1 8 0 2 0 4 0 7\n",
    "2 4 0 0 0 5 0 0 0\n",
    "'''\n",
    "\n",
    "solved_puzzle_nn = solve_sudoku_with_nn(model, game)\n",
    "\n",
    "# Print the solved puzzle as a grid\n",
    "print(\"Sudoku Solution (NN):\")\n",
    "print_sudoku_grid(solved_puzzle_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38a9206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
